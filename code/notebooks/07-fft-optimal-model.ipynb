{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 03: Optimal Model Validation\n",
    "\n",
    "**Purpose**: Deep validation of optimal model through cross-validation, extrapolation, and long-term drift analysis\n",
    "\n",
    "**Inputs**:\n",
    "- `outputs/models/optimal_model.pkl` - Saved HarmonicAnalyzer from Notebook 02\n",
    "- `outputs/csvs/optimal_model_params.csv` - Model parameters\n",
    "\n",
    "**Outputs**:\n",
    "- `outputs/csvs/cv_results.csv` - Cross-validation metrics\n",
    "- `outputs/csvs/drift_analysis.csv` - Long-term drift data\n",
    "- `outputs/csvs/extrapolation_predictions.csv` - Predictions -50k to +100k CE\n",
    "- `outputs/csvs/residual_diagnostics.csv` - Diagnostic statistics\n",
    "- Figures: CV performance, drift analysis, residual diagnostics\n",
    "\n",
    "**Execution time**: ~4-5 minutes\n",
    "\n",
    "---\n",
    "\n",
    "## Key Questions\n",
    "\n",
    "1. **Cross-validation**: Does the model generalize across different time periods?\n",
    "2. **Extrapolation**: How accurate are predictions 50,000+ years beyond the data?\n",
    "3. **Drift**: Does error accumulate (unbounded) or oscillate (bounded)?\n",
    "4. **Precession scale**: What is the error at precession cycle boundaries (\u00b125.7k, \u00b151.5k years)?\n",
    "5. **Residuals**: Are they white noise or is there structure left?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup & Load Optimal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T06:35:17.541929Z",
     "iopub.status.busy": "2025-11-11T06:35:17.541842Z",
     "iopub.status.idle": "2025-11-11T06:35:18.382563Z",
     "shell.execute_reply": "2025-11-11T06:35:18.382334Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2713 Loaded optimal 6-harmonic model\n",
      "  Periods: [14700. 29400.  9800.  7350.  5880.  4900.]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import swisseph as swe\n",
    "import pickle\n",
    "from scipy import stats\n",
    "\n",
    "from src.enoch import enoch_calendar_frame, merge_astronomic_data\n",
    "from src.harmonic_analysis import HarmonicAnalyzer\n",
    "\n",
    "from src.enoch_config import SWISS_EPH_PATH\n",
    "swe.set_ephe_path(SWISS_EPH_PATH)\n",
    "swe.set_jpl_file('de441.eph')\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Load optimal model\n",
    "with open('outputs/models/optimal_model.pkl', 'rb') as f:\n",
    "    analyzer = pickle.load(f)\n",
    "\n",
    "# Load model parameters\n",
    "params_df = pd.read_csv('outputs/csvs/optimal_model_params.csv')\n",
    "n_harmonics = len(params_df) - 1  # -1 for offset row\n",
    "\n",
    "print(f\"\u2713 Loaded optimal {n_harmonics}-harmonic model\")\n",
    "print(f\"  Periods: {params_df['period'].values[:-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Full Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T06:35:18.395596Z",
     "iopub.status.busy": "2025-11-11T06:35:18.395504Z",
     "iopub.status.idle": "2025-11-11T06:35:30.423824Z",
     "shell.execute_reply": "2025-11-11T06:35:30.423558Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2713 Data loaded: 29,400 points (-12762 to 16636 CE)\n"
     ]
    }
   ],
   "source": [
    "YEAR_START = -12762\n",
    "NUM_CYCLES = 100\n",
    "\n",
    "e_df = enoch_calendar_frame(num_cycles=NUM_CYCLES)\n",
    "a_df = merge_astronomic_data(e_df, YEAR_START, use_tt=True)\n",
    "\n",
    "# Calculate solar year\n",
    "a_df['solar_year'] = a_df['enoch_year'] + YEAR_START\n",
    "\n",
    "day1_data = a_df[a_df.enoch_solar_doy == 1].copy()\n",
    "day1_data = day1_data.sort_values('solar_year').reset_index(drop=True)\n",
    "\n",
    "years = day1_data['solar_year'].values\n",
    "ecliptic = day1_data['sun_ecliptic_longitude_neg'].values\n",
    "\n",
    "valid_mask = ~np.isnan(ecliptic)\n",
    "years = years[valid_mask]\n",
    "ecliptic = ecliptic[valid_mask]\n",
    "\n",
    "print(f\"\u2713 Data loaded: {len(years):,} points ({years.min():.0f} to {years.max():.0f} CE)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold Time Series Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T06:35:30.425083Z",
     "iopub.status.busy": "2025-11-11T06:35:30.425014Z",
     "iopub.status.idle": "2025-11-11T06:35:31.286729Z",
     "shell.execute_reply": "2025-11-11T06:35:31.286417Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing 5-Fold Expanding Window Cross-Validation...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/meetri/dev/apps/python/enoch-manuscript/code/src/harmonic_analysis.py:122: RuntimeWarning: Detected irregular year spacing (99 anomalies, median step 1.000000). FFT results now use the median cadence; consider resampling for highest fidelity.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Multi-Harmonic Fit Results ===\n",
      "Fitted 6-frequency model\n",
      "  Component 1: Period=   14700.0 yr, Amplitude= +0.915\u00b0, Phase= +1.932 rad\n",
      "  Component 2: Period=   29400.0 yr, Amplitude= +1.112\u00b0, Phase= -0.011 rad\n",
      "  Component 3: Period=    9800.0 yr, Amplitude= +0.200\u00b0, Phase= -0.371 rad\n",
      "  Component 4: Period=    7350.0 yr, Amplitude= -0.038\u00b0, Phase= +0.553 rad\n",
      "  Component 5: Period=    5880.0 yr, Amplitude= +0.001\u00b0, Phase= +0.741 rad\n",
      "  Component 6: Period=    4900.0 yr, Amplitude= -0.002\u00b0, Phase= -0.304 rad\n",
      "  Offset:  -0.164\u00b0\n",
      "\n",
      "Goodness of fit:\n",
      "  R\u00b2 = 0.922746\n",
      "  RMSE = 0.282\u00b0\n",
      "Fold 1: Train [-12762, 1936] \u2192 Test [1938, 4876]\n",
      "  CV RMSE: 0.2948\u00b0, CV R\u00b2: 0.148405\n",
      "\n",
      "=== Multi-Harmonic Fit Results ===\n",
      "Fitted 6-frequency model\n",
      "  Component 1: Period=   14700.0 yr, Amplitude= +0.931\u00b0, Phase= +2.084 rad\n",
      "  Component 2: Period=   29400.0 yr, Amplitude= +1.300\u00b0, Phase= -0.103 rad\n",
      "  Component 3: Period=    9800.0 yr, Amplitude= +0.223\u00b0, Phase= -0.051 rad\n",
      "  Component 4: Period=    7350.0 yr, Amplitude= -0.065\u00b0, Phase= +1.009 rad\n",
      "  Component 5: Period=    5880.0 yr, Amplitude= +0.017\u00b0, Phase= +2.080 rad\n",
      "  Component 6: Period=    4900.0 yr, Amplitude= +0.003\u00b0, Phase= +0.052 rad\n",
      "  Offset:  -0.038\u00b0\n",
      "\n",
      "Goodness of fit:\n",
      "  R\u00b2 = 0.930013\n",
      "  RMSE = 0.283\u00b0\n",
      "Fold 2: Train [-12762, 4876] \u2192 Test [4878, 7816]\n",
      "  CV RMSE: 0.3291\u00b0, CV R\u00b2: -0.076955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/meetri/dev/apps/python/enoch-manuscript/code/src/harmonic_analysis.py:122: RuntimeWarning: Detected irregular year spacing (119 anomalies, median step 1.000000). FFT results now use the median cadence; consider resampling for highest fidelity.\n",
      "  warnings.warn(\n",
      "/Users/meetri/dev/apps/python/enoch-manuscript/code/src/harmonic_analysis.py:122: RuntimeWarning: Detected irregular year spacing (139 anomalies, median step 1.000000). FFT results now use the median cadence; consider resampling for highest fidelity.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Multi-Harmonic Fit Results ===\n",
      "Fitted 6-frequency model\n",
      "  Component 1: Period=   14700.0 yr, Amplitude= +0.854\u00b0, Phase= +1.810 rad\n",
      "  Component 2: Period=   29400.0 yr, Amplitude= +1.054\u00b0, Phase= +0.088 rad\n",
      "  Component 3: Period=    9800.0 yr, Amplitude= -0.183\u00b0, Phase= +2.289 rad\n",
      "  Component 4: Period=    7350.0 yr, Amplitude= +0.052\u00b0, Phase= +2.610 rad\n",
      "  Component 5: Period=    5880.0 yr, Amplitude= -0.016\u00b0, Phase= +2.951 rad\n",
      "  Component 6: Period=    4900.0 yr, Amplitude= +0.004\u00b0, Phase= +3.298 rad\n",
      "  Offset:  -0.219\u00b0\n",
      "\n",
      "Goodness of fit:\n",
      "  R\u00b2 = 0.922812\n",
      "  RMSE = 0.285\u00b0\n",
      "Fold 3: Train [-12762, 7816] \u2192 Test [7818, 10756]\n",
      "  CV RMSE: 0.2914\u00b0, CV R\u00b2: 0.313217\n",
      "\n",
      "=== Multi-Harmonic Fit Results ===\n",
      "Fitted 6-frequency model\n",
      "  Component 1: Period=   14700.0 yr, Amplitude= -0.880\u00b0, Phase= -1.315 rad\n",
      "  Component 2: Period=   29400.0 yr, Amplitude= +1.065\u00b0, Phase= +0.055 rad\n",
      "  Component 3: Period=    9800.0 yr, Amplitude= +0.204\u00b0, Phase= -0.809 rad\n",
      "  Component 4: Period=    7350.0 yr, Amplitude= -0.066\u00b0, Phase= -0.436 rad\n",
      "  Component 5: Period=    5880.0 yr, Amplitude= +0.024\u00b0, Phase= -0.044 rad\n",
      "  Component 6: Period=    4900.0 yr, Amplitude= -0.007\u00b0, Phase= +0.370 rad\n",
      "  Offset:  -0.200\u00b0\n",
      "\n",
      "Goodness of fit:\n",
      "  R\u00b2 = 0.916940\n",
      "  RMSE = 0.286\u00b0\n",
      "Fold 4: Train [-12762, 10756] \u2192 Test [10758, 13696]\n",
      "  CV RMSE: 0.6294\u00b0, CV R\u00b2: -0.075284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/meetri/dev/apps/python/enoch-manuscript/code/src/harmonic_analysis.py:122: RuntimeWarning: Detected irregular year spacing (159 anomalies, median step 1.000000). FFT results now use the median cadence; consider resampling for highest fidelity.\n",
      "  warnings.warn(\n",
      "/Users/meetri/dev/apps/python/enoch-manuscript/code/src/harmonic_analysis.py:122: RuntimeWarning: Detected irregular year spacing (179 anomalies, median step 1.000000). FFT results now use the median cadence; consider resampling for highest fidelity.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Multi-Harmonic Fit Results ===\n",
      "Fitted 6-frequency model\n",
      "  Component 1: Period=   14700.0 yr, Amplitude= -1.090\u00b0, Phase= -1.323 rad\n",
      "  Component 2: Period=   29400.0 yr, Amplitude= +1.101\u00b0, Phase= -0.155 rad\n",
      "  Component 3: Period=    9800.0 yr, Amplitude= +0.373\u00b0, Phase= -1.016 rad\n",
      "  Component 4: Period=    7350.0 yr, Amplitude= -0.196\u00b0, Phase= -0.933 rad\n",
      "  Component 5: Period=    5880.0 yr, Amplitude= +0.117\u00b0, Phase= -0.892 rad\n",
      "  Component 6: Period=    4900.0 yr, Amplitude= -0.069\u00b0, Phase= -0.879 rad\n",
      "  Offset:  -0.081\u00b0\n",
      "\n",
      "Goodness of fit:\n",
      "  R\u00b2 = 0.933613\n",
      "  RMSE = 0.289\u00b0\n",
      "Fold 5: Train [-12762, 13696] \u2192 Test [13698, 16636]\n",
      "  CV RMSE: 2.7281\u00b0, CV R\u00b2: -13.769836\n",
      "\n",
      "Cross-Validation Summary:\n",
      "  Mean CV RMSE: 0.8546\u00b0 \u00b1 1.0568\u00b0\n",
      "  Mean CV R\u00b2: -2.692090\n",
      "\n",
      "\u2713 CV results saved: outputs/csvs/cv_results.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"Performing 5-Fold Expanding Window Cross-Validation...\\n\")\n",
    "\n",
    "K_FOLDS = 5\n",
    "cv_results = []\n",
    "\n",
    "# Calculate fold boundaries\n",
    "n_total = len(years)\n",
    "initial_train_size = int(n_total * 0.5)  # Start with 50% for training\n",
    "test_size = int((n_total - initial_train_size) / K_FOLDS)\n",
    "\n",
    "for fold in range(K_FOLDS):\n",
    "    # Expanding window: train size grows, test moves forward\n",
    "    train_end_idx = initial_train_size + fold * test_size\n",
    "    test_start_idx = train_end_idx\n",
    "    test_end_idx = test_start_idx + test_size\n",
    "    \n",
    "    years_train_cv = years[:train_end_idx]\n",
    "    ecliptic_train_cv = ecliptic[:train_end_idx]\n",
    "    \n",
    "    years_test_cv = years[test_start_idx:test_end_idx]\n",
    "    ecliptic_test_cv = ecliptic[test_start_idx:test_end_idx]\n",
    "    \n",
    "    # Fit model on this fold's training data\n",
    "    analyzer_cv = HarmonicAnalyzer(years_train_cv, ecliptic_train_cv)\n",
    "    periods = params_df['period'].values[:-1]  # Exclude offset\n",
    "    fit_cv = analyzer_cv.fit_multi_harmonic(periods.tolist())\n",
    "    \n",
    "    # Predict on test fold\n",
    "    test_pred_cv = analyzer_cv.predict(years_test_cv)\n",
    "    test_resid_cv = ecliptic_test_cv - test_pred_cv\n",
    "    cv_rmse = np.sqrt(np.mean(test_resid_cv**2))\n",
    "    cv_r2 = 1 - (np.sum(test_resid_cv**2) / np.sum((ecliptic_test_cv - np.mean(ecliptic_test_cv))**2))\n",
    "    \n",
    "    cv_results.append({\n",
    "        'fold': fold + 1,\n",
    "        'train_start': years_train_cv[0],\n",
    "        'train_end': years_train_cv[-1],\n",
    "        'test_start': years_test_cv[0],\n",
    "        'test_end': years_test_cv[-1],\n",
    "        'train_size': len(years_train_cv),\n",
    "        'test_size': len(years_test_cv),\n",
    "        'cv_rmse': cv_rmse,\n",
    "        'cv_r2': cv_r2\n",
    "    })\n",
    "    \n",
    "    print(f\"Fold {fold+1}: Train [{years_train_cv[0]:.0f}, {years_train_cv[-1]:.0f}] \u2192 Test [{years_test_cv[0]:.0f}, {years_test_cv[-1]:.0f}]\")\n",
    "    print(f\"  CV RMSE: {cv_rmse:.4f}\u00b0, CV R\u00b2: {cv_r2:.6f}\")\n",
    "\n",
    "cv_df = pd.DataFrame(cv_results)\n",
    "mean_cv_rmse = cv_df['cv_rmse'].mean()\n",
    "std_cv_rmse = cv_df['cv_rmse'].std()\n",
    "\n",
    "print(f\"\\nCross-Validation Summary:\")\n",
    "print(f\"  Mean CV RMSE: {mean_cv_rmse:.4f}\u00b0 \u00b1 {std_cv_rmse:.4f}\u00b0\")\n",
    "print(f\"  Mean CV R\u00b2: {cv_df['cv_r2'].mean():.6f}\")\n",
    "\n",
    "cv_df.to_csv('outputs/csvs/cv_results.csv', index=False)\n",
    "print(f\"\\n\u2713 CV results saved: outputs/csvs/cv_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Long-Term Extrapolation & Drift Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T06:35:31.287978Z",
     "iopub.status.busy": "2025-11-11T06:35:31.287909Z",
     "iopub.status.idle": "2025-11-11T06:35:31.294018Z",
     "shell.execute_reply": "2025-11-11T06:35:31.293798Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating long-term extrapolation (-50,000 to +100,000 CE)...\n",
      "\n",
      "Drift Analysis:\n",
      "  Drift rate: -0.013152 \u00b0/millennium\n",
      "  p-value: 0.028431 (significant)\n",
      "  Error at precession boundaries:\n",
      "         +0 yr:   -0.51\u00b0 (|0.51\u00b0|)\n",
      "     +25772 yr:   +0.98\u00b0 (|0.98\u00b0|)\n",
      "     +51544 yr:   +0.36\u00b0 (|0.36\u00b0|)\n",
      "     +77316 yr:   -0.16\u00b0 (|0.16\u00b0|)\n",
      "     -25772 yr:   -1.98\u00b0 (|1.98\u00b0|)\n",
      "     -51544 yr:   -1.66\u00b0 (|1.66\u00b0|)\n",
      "\n",
      "\u2713 Extrapolation predictions saved: outputs/csvs/extrapolation_predictions.csv\n",
      "\u2713 Drift analysis saved: outputs/csvs/drift_analysis.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating long-term extrapolation (-50,000 to +100,000 CE)...\\n\")\n",
    "\n",
    "# Generate prediction years\n",
    "extrap_years = np.arange(-50000, 100001, 100)  # Every 100 years\n",
    "extrap_predictions = analyzer.predict(extrap_years)\n",
    "\n",
    "# Calculate drift metrics at key horizons\n",
    "PRECESSION_PERIOD = 25772\n",
    "data_end = years.max()\n",
    "\n",
    "# Precession cycle boundaries relative to data end\n",
    "boundaries = [0, PRECESSION_PERIOD, 2*PRECESSION_PERIOD, 3*PRECESSION_PERIOD, -PRECESSION_PERIOD, -2*PRECESSION_PERIOD]\n",
    "\n",
    "drift_analysis = []\n",
    "for boundary_offset in boundaries:\n",
    "    target_year = data_end + boundary_offset\n",
    "    if target_year < extrap_years.min() or target_year > extrap_years.max():\n",
    "        continue\n",
    "    \n",
    "    # Find closest prediction\n",
    "    idx = np.argmin(np.abs(extrap_years - target_year))\n",
    "    pred_value = extrap_predictions[idx]\n",
    "    \n",
    "    drift_analysis.append({\n",
    "        'time_horizon': boundary_offset,\n",
    "        'year': extrap_years[idx],\n",
    "        'predicted_value': pred_value,\n",
    "        'abs_predicted_value': np.abs(pred_value)\n",
    "    })\n",
    "\n",
    "drift_df = pd.DataFrame(drift_analysis)\n",
    "\n",
    "# Calculate drift rate (linear regression on absolute predictions vs time)\n",
    "from scipy.stats import linregress\n",
    "slope, intercept, r_value, p_value, std_err = linregress(\n",
    "    drift_df['time_horizon'], \n",
    "    drift_df['abs_predicted_value']\n",
    ")\n",
    "\n",
    "drift_rate_per_millennium = slope * 1000  # Convert to \u00b0/millennium\n",
    "\n",
    "print(f\"Drift Analysis:\")\n",
    "print(f\"  Drift rate: {drift_rate_per_millennium:.6f} \u00b0/millennium\")\n",
    "print(f\"  p-value: {p_value:.6f} ({'significant' if p_value < 0.05 else 'not significant'})\")\n",
    "print(f\"  Error at precession boundaries:\")\n",
    "for _, row in drift_df.iterrows():\n",
    "    print(f\"    {row['time_horizon']:+7.0f} yr: {row['predicted_value']:+7.2f}\u00b0 (|{row['abs_predicted_value']:.2f}\u00b0|)\")\n",
    "\n",
    "# Save extrapolation predictions\n",
    "extrap_df = pd.DataFrame({\n",
    "    'year': extrap_years,\n",
    "    'predicted_longitude': extrap_predictions\n",
    "})\n",
    "extrap_df.to_csv('outputs/csvs/extrapolation_predictions.csv', index=False)\n",
    "print(f\"\\n\u2713 Extrapolation predictions saved: outputs/csvs/extrapolation_predictions.csv\")\n",
    "\n",
    "drift_df.to_csv('outputs/csvs/drift_analysis.csv', index=False)\n",
    "print(f\"\u2713 Drift analysis saved: outputs/csvs/drift_analysis.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T06:35:31.295287Z",
     "iopub.status.busy": "2025-11-11T06:35:31.295222Z",
     "iopub.status.idle": "2025-11-11T06:35:31.300080Z",
     "shell.execute_reply": "2025-11-11T06:35:31.299875Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual Diagnostics:\n",
      "  Mean: 0.000000\u00b0 (should be ~0)\n",
      "  Std: 0.2029\u00b0\n",
      "  Range: [-0.65\u00b0, 0.64\u00b0]\n",
      "  Normality p-value: 0.000000\n",
      "  Autocorrelation (lag-1): -0.2657\n",
      "\n",
      "\u2713 Residual diagnostics saved: outputs/csvs/residual_diagnostics.csv\n"
     ]
    }
   ],
   "source": [
    "# Get residuals from optimal model fit on training data\n",
    "# (Refit if needed or extract from saved model)\n",
    "fitted_values = analyzer.predict(analyzer.years)\n",
    "residuals = analyzer.values - fitted_values\n",
    "\n",
    "# Compute diagnostics\n",
    "diagnostics = {\n",
    "    'residual_mean': np.mean(residuals),\n",
    "    'residual_std': np.std(residuals),\n",
    "    'residual_min': np.min(residuals),\n",
    "    'residual_max': np.max(residuals),\n",
    "    'residual_range': np.max(residuals) - np.min(residuals),\n",
    "    'residual_skewness': stats.skew(residuals),\n",
    "    'residual_kurtosis': stats.kurtosis(residuals),\n",
    "    'normality_pvalue': stats.normaltest(residuals).pvalue,\n",
    "    'autocorr_lag1': np.corrcoef(residuals[:-1], residuals[1:])[0, 1]\n",
    "}\n",
    "\n",
    "diag_df = pd.DataFrame([diagnostics])\n",
    "diag_df.to_csv('outputs/csvs/residual_diagnostics.csv', index=False)\n",
    "\n",
    "print(\"Residual Diagnostics:\")\n",
    "print(f\"  Mean: {diagnostics['residual_mean']:.6f}\u00b0 (should be ~0)\")\n",
    "print(f\"  Std: {diagnostics['residual_std']:.4f}\u00b0\")\n",
    "print(f\"  Range: [{diagnostics['residual_min']:.2f}\u00b0, {diagnostics['residual_max']:.2f}\u00b0]\")\n",
    "print(f\"  Normality p-value: {diagnostics['normality_pvalue']:.6f}\")\n",
    "print(f\"  Autocorrelation (lag-1): {diagnostics['autocorr_lag1']:.4f}\")\n",
    "print(f\"\\n\u2713 Residual diagnostics saved: outputs/csvs/residual_diagnostics.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T06:35:31.301176Z",
     "iopub.status.busy": "2025-11-11T06:35:31.301113Z",
     "iopub.status.idle": "2025-11-11T06:35:31.303801Z",
     "shell.execute_reply": "2025-11-11T06:35:31.303611Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "OPTIMAL MODEL VALIDATION SUMMARY\n",
      "======================================================================\n",
      "\n",
      "Model: 6-harmonic optimal model\n",
      "\n",
      "Cross-Validation (K=5):\n",
      "  Mean CV RMSE: 0.8546\u00b0 \u00b1 1.0568\u00b0\n",
      "  Stability: Moderate\n",
      "\n",
      "Long-Term Drift:\n",
      "  Drift rate: -0.013152 \u00b0/millennium\n",
      "  Statistical significance: p=0.028431 (Yes)\n",
      "  Behavior: Possible secular drift\n",
      "\n",
      "Precession-Scale Error:\n",
      "  Maximum error at boundaries: 1.98\u00b0\n",
      "  Within \u00b115\u00b0 bounds: Yes \u2713\n",
      "\n",
      "Residual Quality:\n",
      "  White noise test: Fail \u2717 (p=0.0000)\n",
      "  Autocorrelation: -0.2657 (Low)\n",
      "\n",
      "======================================================================\n",
      "\u2713 Notebook 03 complete\n",
      "======================================================================\n",
      "\n",
      "Next step: Run Notebook 04 (294-Multiple Resonance)\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"OPTIMAL MODEL VALIDATION SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nModel: {n_harmonics}-harmonic optimal model\")\n",
    "\n",
    "print(f\"\\nCross-Validation (K={K_FOLDS}):\")\n",
    "print(f\"  Mean CV RMSE: {mean_cv_rmse:.4f}\u00b0 \u00b1 {std_cv_rmse:.4f}\u00b0\")\n",
    "print(f\"  Stability: {'Excellent' if std_cv_rmse < 0.1 else 'Good' if std_cv_rmse < 0.3 else 'Moderate'}\")\n",
    "\n",
    "print(f\"\\nLong-Term Drift:\")\n",
    "print(f\"  Drift rate: {drift_rate_per_millennium:.6f} \u00b0/millennium\")\n",
    "print(f\"  Statistical significance: p={p_value:.6f} ({'Yes' if p_value < 0.05 else 'No'})\")\n",
    "print(f\"  Behavior: {'Bounded oscillation' if abs(drift_rate_per_millennium) < 0.01 else 'Possible secular drift'}\")\n",
    "\n",
    "print(f\"\\nPrecession-Scale Error:\")\n",
    "max_error_at_boundaries = drift_df['abs_predicted_value'].max()\n",
    "print(f\"  Maximum error at boundaries: {max_error_at_boundaries:.2f}\u00b0\")\n",
    "print(f\"  Within \u00b115\u00b0 bounds: {'Yes \u2713' if max_error_at_boundaries <= 15 else 'No \u2717'}\")\n",
    "\n",
    "print(f\"\\nResidual Quality:\")\n",
    "print(f\"  White noise test: {'Pass \u2713' if diagnostics['normality_pvalue'] > 0.05 else 'Fail \u2717'} (p={diagnostics['normality_pvalue']:.4f})\")\n",
    "print(f\"  Autocorrelation: {diagnostics['autocorr_lag1']:.4f} ({'Low' if abs(diagnostics['autocorr_lag1']) < 0.3 else 'Moderate'})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"\u2713 Notebook 03 complete\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nNext step: Run Notebook 04 (294-Multiple Resonance)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}